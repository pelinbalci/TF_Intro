{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lecture_8_transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTISy6iTjlEXkrb6QQZG2d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pelinbalci/TF_Intro/blob/main/lecture_8_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RpfD3Inl4XN"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEtfbVyZlvp_"
      },
      "source": [
        "References:\n",
        "\n",
        "- https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%206%20-%20Lesson%203%20-%20Notebook.ipynb\n",
        "\n",
        "- https://www.coursera.org/learn/convolutional-neural-networks-tensorflow/\n",
        "\n",
        "- https://www.tensorflow.org/tutorials/images/transfer_learning\n",
        "\n",
        "- To prevent overfitting use dropout: https://www.youtube.com/watch?v=ARq74QuavAo&ab_channel=DeepLearningAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUxyvsiomQxt"
      },
      "source": [
        "This part is copied from: https://www.tensorflow.org/tutorials/images/transfer_learning\n",
        "\n",
        "\n",
        "\"You either use the pretrained model as is or use transfer learning to customize this model to a given task.\"\n",
        "\n",
        "\"\n",
        "### Summary\n",
        "- Using a pre-trained model for feature extraction: When working with a small dataset, it is a common practice to take advantage of features learned by a model trained on a larger dataset in the same domain. This is done by instantiating the pre-trained model and adding a fully-connected classifier on top. The pre-trained model is \"frozen\" and only the weights of the classifier get updated during training. In this case, the convolutional base extracted all the features associated with each image and you just trained a classifier that determines the image class given that set of extracted features.\n",
        "\n",
        "- Fine-tuning a pre-trained model: To further improve performance, one might want to repurpose the top-level layers of the pre-trained models to the new dataset via fine-tuning. In this case, you tuned your weights such that your model learned high-level features specific to the dataset. This technique is usually recommended when the training dataset is large and very similar to the original dataset that the pre-trained model was trained on.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioJbddGVwWLr"
      },
      "source": [
        "Without dropout: \n",
        "\n",
        "100/100 - 18s - loss: 0.1216 - accuracy: 0.9605 - val_loss: 0.1320 - val_accuracy: 0.9700\n",
        "\n",
        "\n",
        "```And the idea behind the dropout is that layers in a neural network can sometimes end up having similar weights and possible impact each other leading to over-fitting. With a big complex model like this, that's a risk.  ```\n",
        "\n",
        "With Dropout:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6fJ1559lsR3",
        "outputId": "6138f58e-efaa-4806-9d67-ba6e13d227d1"
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False,   # ignore the top layer \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False   # lock layers. we don't want to retrain them. \n",
        "  \n",
        "pre_trained_model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-23 15:17:57--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 108.177.97.128, 108.177.125.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   123MB/s    in 0.7s    \n",
            "\n",
            "2021-05-23 15:17:59 (123 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 74, 74, 32)   864         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 74, 74, 32)   96          conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 74, 74, 32)   0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 72, 72, 32)   9216        activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 72, 72, 32)   96          conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 72, 72, 32)   0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 72, 72, 64)   18432       activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 72, 72, 64)   192         conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 72, 72, 64)   0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 35, 35, 80)   240         conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 35, 35, 80)   0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 33, 33, 192)  138240      activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 33, 33, 192)  576         conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 33, 33, 192)  0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 16, 16, 64)   192         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 16, 16, 64)   0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 16, 16, 96)   55296       activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 16, 16, 48)   144         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 16, 16, 96)   288         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 16, 16, 48)   0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 16, 16, 96)   0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_18 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 16, 16, 64)   76800       activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 16, 16, 96)   82944       activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 16, 16, 64)   192         conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 16, 16, 64)   192         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 16, 16, 96)   288         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 16, 16, 32)   96          conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 16, 16, 64)   0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 16, 16, 64)   0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 16, 16, 96)   0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 16, 16, 32)   0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_193[0][0]             \n",
            "                                                                 activation_195[0][0]             \n",
            "                                                                 activation_198[0][0]             \n",
            "                                                                 activation_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 16, 16, 64)   192         conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 16, 16, 64)   0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 16, 16, 96)   55296       activation_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 16, 16, 48)   144         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, 16, 16, 96)   288         conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 16, 16, 48)   0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 16, 16, 96)   0           batch_normalization_204[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_19 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 16, 16, 64)   76800       activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 16, 16, 96)   82944       activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 16, 16, 64)   192         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 16, 16, 64)   192         conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, 16, 16, 96)   288         conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 16, 16, 64)   192         conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 16, 16, 64)   0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 16, 16, 64)   0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 16, 16, 96)   0           batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 16, 16, 64)   0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_200[0][0]             \n",
            "                                                                 activation_202[0][0]             \n",
            "                                                                 activation_205[0][0]             \n",
            "                                                                 activation_206[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 16, 16, 64)   192         conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 16, 16, 64)   0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 16, 16, 96)   55296       activation_210[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 16, 16, 48)   144         conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 16, 16, 96)   288         conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 16, 16, 48)   0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 16, 16, 96)   0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_20 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 16, 16, 64)   76800       activation_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 16, 16, 96)   82944       activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 16, 16, 64)   192         conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 16, 16, 64)   192         conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 16, 16, 96)   288         conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, 16, 16, 64)   192         conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 16, 16, 64)   0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 16, 16, 64)   0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 16, 16, 96)   0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 16, 16, 64)   0           batch_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_207[0][0]             \n",
            "                                                                 activation_209[0][0]             \n",
            "                                                                 activation_212[0][0]             \n",
            "                                                                 activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, 16, 16, 64)   192         conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 16, 16, 64)   0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 16, 16, 96)   55296       activation_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 16, 16, 96)   288         conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 16, 16, 96)   0           batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 7, 7, 96)     82944       activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, 7, 7, 384)    1152        conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 7, 7, 96)     288         conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 7, 7, 384)    0           batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 7, 7, 96)     0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_214[0][0]             \n",
            "                                                                 activation_217[0][0]             \n",
            "                                                                 max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, 7, 7, 128)    384         conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 7, 7, 128)    0           batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 7, 7, 128)    114688      activation_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, 7, 7, 128)    384         conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 7, 7, 128)    114688      activation_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 7, 7, 128)    384         conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, 7, 7, 128)    384         conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 7, 7, 128)    0           batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 7, 7, 128)    0           batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 7, 7, 128)    114688      activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 7, 7, 128)    114688      activation_224[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 7, 7, 128)    384         conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_225 (BatchN (None, 7, 7, 128)    384         conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 7, 7, 128)    0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 7, 7, 128)    0           batch_normalization_225[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_21 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 7, 7, 192)    172032      activation_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 7, 7, 192)    172032      activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_21[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 7, 7, 192)    576         conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, 7, 7, 192)    576         conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_226 (BatchN (None, 7, 7, 192)    576         conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_227 (BatchN (None, 7, 7, 192)    576         conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 7, 7, 192)    0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 7, 7, 192)    0           batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 7, 7, 192)    0           batch_normalization_226[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 7, 7, 192)    0           batch_normalization_227[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_218[0][0]             \n",
            "                                                                 activation_221[0][0]             \n",
            "                                                                 activation_226[0][0]             \n",
            "                                                                 activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_232 (BatchN (None, 7, 7, 160)    480         conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 7, 7, 160)    0           batch_normalization_232[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 7, 7, 160)    179200      activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_233 (BatchN (None, 7, 7, 160)    480         conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 7, 7, 160)    0           batch_normalization_233[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 7, 7, 160)    179200      activation_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_229 (BatchN (None, 7, 7, 160)    480         conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_234 (BatchN (None, 7, 7, 160)    480         conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 7, 7, 160)    0           batch_normalization_229[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 7, 7, 160)    0           batch_normalization_234[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 7, 7, 160)    179200      activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 7, 7, 160)    179200      activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_230 (BatchN (None, 7, 7, 160)    480         conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_235 (BatchN (None, 7, 7, 160)    480         conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 7, 7, 160)    0           batch_normalization_230[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 7, 7, 160)    0           batch_normalization_235[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_22 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 7, 7, 192)    215040      activation_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 7, 7, 192)    215040      activation_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_22[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_228 (BatchN (None, 7, 7, 192)    576         conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_231 (BatchN (None, 7, 7, 192)    576         conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_236 (BatchN (None, 7, 7, 192)    576         conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_237 (BatchN (None, 7, 7, 192)    576         conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 7, 7, 192)    0           batch_normalization_228[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 7, 7, 192)    0           batch_normalization_231[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, 7, 7, 192)    0           batch_normalization_236[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 7, 7, 192)    0           batch_normalization_237[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_228[0][0]             \n",
            "                                                                 activation_231[0][0]             \n",
            "                                                                 activation_236[0][0]             \n",
            "                                                                 activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_242 (BatchN (None, 7, 7, 160)    480         conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, 7, 7, 160)    0           batch_normalization_242[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 7, 7, 160)    179200      activation_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_243 (BatchN (None, 7, 7, 160)    480         conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 7, 7, 160)    0           batch_normalization_243[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 7, 7, 160)    179200      activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_239 (BatchN (None, 7, 7, 160)    480         conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_244 (BatchN (None, 7, 7, 160)    480         conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, 7, 7, 160)    0           batch_normalization_239[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 7, 7, 160)    0           batch_normalization_244[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 7, 7, 160)    179200      activation_239[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 7, 7, 160)    179200      activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_240 (BatchN (None, 7, 7, 160)    480         conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_245 (BatchN (None, 7, 7, 160)    480         conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 7, 7, 160)    0           batch_normalization_240[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 7, 7, 160)    0           batch_normalization_245[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_23 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 7, 7, 192)    215040      activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 7, 7, 192)    215040      activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_23[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_238 (BatchN (None, 7, 7, 192)    576         conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_241 (BatchN (None, 7, 7, 192)    576         conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_246 (BatchN (None, 7, 7, 192)    576         conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_247 (BatchN (None, 7, 7, 192)    576         conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, 7, 7, 192)    0           batch_normalization_238[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 7, 7, 192)    0           batch_normalization_241[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 7, 7, 192)    0           batch_normalization_246[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, 7, 7, 192)    0           batch_normalization_247[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_238[0][0]             \n",
            "                                                                 activation_241[0][0]             \n",
            "                                                                 activation_246[0][0]             \n",
            "                                                                 activation_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, 7, 7, 192)    576         conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 7, 7, 192)    0           batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, 7, 7, 192)    258048      activation_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_253 (BatchN (None, 7, 7, 192)    576         conv2d_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_253 (Activation)     (None, 7, 7, 192)    0           batch_normalization_253[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, 7, 7, 192)    258048      activation_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 7, 7, 192)    576         conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_254 (BatchN (None, 7, 7, 192)    576         conv2d_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 7, 7, 192)    0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_254 (Activation)     (None, 7, 7, 192)    0           batch_normalization_254[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 7, 7, 192)    258048      activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, 7, 7, 192)    258048      activation_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 7, 7, 192)    576         conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_255 (BatchN (None, 7, 7, 192)    576         conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 7, 7, 192)    0           batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_255 (Activation)     (None, 7, 7, 192)    0           batch_normalization_255[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_24 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 7, 7, 192)    258048      activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_256 (Conv2D)             (None, 7, 7, 192)    258048      activation_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_257 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_248 (BatchN (None, 7, 7, 192)    576         conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 7, 7, 192)    576         conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_256 (BatchN (None, 7, 7, 192)    576         conv2d_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_257 (BatchN (None, 7, 7, 192)    576         conv2d_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, 7, 7, 192)    0           batch_normalization_248[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 7, 7, 192)    0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_256 (Activation)     (None, 7, 7, 192)    0           batch_normalization_256[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_257 (Activation)     (None, 7, 7, 192)    0           batch_normalization_257[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
            "                                                                 activation_251[0][0]             \n",
            "                                                                 activation_256[0][0]             \n",
            "                                                                 activation_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_260 (BatchN (None, 7, 7, 192)    576         conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_260 (Activation)     (None, 7, 7, 192)    0           batch_normalization_260[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 7, 7, 192)    258048      activation_260[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_261 (BatchN (None, 7, 7, 192)    576         conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_261 (Activation)     (None, 7, 7, 192)    0           batch_normalization_261[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_258 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 7, 7, 192)    258048      activation_261[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_258 (BatchN (None, 7, 7, 192)    576         conv2d_258[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_262 (BatchN (None, 7, 7, 192)    576         conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_258 (Activation)     (None, 7, 7, 192)    0           batch_normalization_258[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_262 (Activation)     (None, 7, 7, 192)    0           batch_normalization_262[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_259 (Conv2D)             (None, 3, 3, 320)    552960      activation_258[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 3, 3, 192)    331776      activation_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_259 (BatchN (None, 3, 3, 320)    960         conv2d_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_263 (BatchN (None, 3, 3, 192)    576         conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_259 (Activation)     (None, 3, 3, 320)    0           batch_normalization_259[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_263 (Activation)     (None, 3, 3, 192)    0           batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_259[0][0]             \n",
            "                                                                 activation_263[0][0]             \n",
            "                                                                 max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_268 (BatchN (None, 3, 3, 448)    1344        conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_268 (Activation)     (None, 3, 3, 448)    0           batch_normalization_268[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, 3, 3, 384)    1548288     activation_268[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_265 (BatchN (None, 3, 3, 384)    1152        conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_269 (BatchN (None, 3, 3, 384)    1152        conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_265 (Activation)     (None, 3, 3, 384)    0           batch_normalization_265[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_269 (Activation)     (None, 3, 3, 384)    0           batch_normalization_269[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 3, 3, 384)    442368      activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, 3, 3, 384)    442368      activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_270 (Conv2D)             (None, 3, 3, 384)    442368      activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_271 (Conv2D)             (None, 3, 3, 384)    442368      activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_25 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_266 (BatchN (None, 3, 3, 384)    1152        conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_267 (BatchN (None, 3, 3, 384)    1152        conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_270 (BatchN (None, 3, 3, 384)    1152        conv2d_270[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_271 (BatchN (None, 3, 3, 384)    1152        conv2d_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_272 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_25[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_264 (BatchN (None, 3, 3, 320)    960         conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_266 (Activation)     (None, 3, 3, 384)    0           batch_normalization_266[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_267 (Activation)     (None, 3, 3, 384)    0           batch_normalization_267[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_270 (Activation)     (None, 3, 3, 384)    0           batch_normalization_270[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_271 (Activation)     (None, 3, 3, 384)    0           batch_normalization_271[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_272 (BatchN (None, 3, 3, 192)    576         conv2d_272[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_264 (Activation)     (None, 3, 3, 320)    0           batch_normalization_264[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_266[0][0]             \n",
            "                                                                 activation_267[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 3, 3, 768)    0           activation_270[0][0]             \n",
            "                                                                 activation_271[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_272 (Activation)     (None, 3, 3, 192)    0           batch_normalization_272[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_264[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_4[0][0]              \n",
            "                                                                 activation_272[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_277 (BatchN (None, 3, 3, 448)    1344        conv2d_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_277 (Activation)     (None, 3, 3, 448)    0           batch_normalization_277[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_274 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, 3, 3, 384)    1548288     activation_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_274 (BatchN (None, 3, 3, 384)    1152        conv2d_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_278 (BatchN (None, 3, 3, 384)    1152        conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_274 (Activation)     (None, 3, 3, 384)    0           batch_normalization_274[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_278 (Activation)     (None, 3, 3, 384)    0           batch_normalization_278[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, 3, 3, 384)    442368      activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, 3, 3, 384)    442368      activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, 3, 3, 384)    442368      activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, 3, 3, 384)    442368      activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_26 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_273 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_275 (BatchN (None, 3, 3, 384)    1152        conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_276 (BatchN (None, 3, 3, 384)    1152        conv2d_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_279 (BatchN (None, 3, 3, 384)    1152        conv2d_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_280 (BatchN (None, 3, 3, 384)    1152        conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_26[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_273 (BatchN (None, 3, 3, 320)    960         conv2d_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_275 (Activation)     (None, 3, 3, 384)    0           batch_normalization_275[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_276 (Activation)     (None, 3, 3, 384)    0           batch_normalization_276[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_279 (Activation)     (None, 3, 3, 384)    0           batch_normalization_279[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_280 (Activation)     (None, 3, 3, 384)    0           batch_normalization_280[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_281 (BatchN (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_273[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
            "                                                                 activation_276[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
            "                                                                 activation_280[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_281[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_5[0][0]              \n",
            "                                                                 activation_281[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sejbAYSgqnoL",
        "outputId": "3c84a176-cb64-41dd-a9ca-74bf1e952185"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ8EXtQ1nOgl"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "# x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqtfVsrDnVwC",
        "outputId": "920e10b2-e16b-45d8-a95a-9e3f4471ef8b"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "       -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/cats_and_dogs_filtered.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Define our example directories and files\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "\n",
        "train_dir = os.path.join( base_dir, 'train')\n",
        "validation_dir = os.path.join( base_dir, 'validation')\n",
        "\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats') # Directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs') # Directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats') # Directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')# Directory with our validation dog pictures\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-23 15:18:02--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.188.128, 64.233.189.128, 108.177.97.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.188.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   155MB/s    in 0.4s    \n",
            "\n",
            "2021-05-23 15:18:02 (155 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWUzGfLDnW3t",
        "outputId": "52b9abe6-3e3a-4049-f1da-e2c4ec2e2b70"
      },
      "source": [
        "history = model.fit(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.3285 - accuracy: 0.8675 - val_loss: 0.1267 - val_accuracy: 0.9560\n",
            "Epoch 2/100\n",
            "100/100 - 19s - loss: 0.2021 - accuracy: 0.9255 - val_loss: 0.1420 - val_accuracy: 0.9530\n",
            "Epoch 3/100\n",
            "100/100 - 19s - loss: 0.1932 - accuracy: 0.9270 - val_loss: 0.1978 - val_accuracy: 0.9410\n",
            "Epoch 4/100\n",
            "100/100 - 18s - loss: 0.1812 - accuracy: 0.9295 - val_loss: 0.1147 - val_accuracy: 0.9640\n",
            "Epoch 5/100\n",
            "100/100 - 18s - loss: 0.1770 - accuracy: 0.9335 - val_loss: 0.1128 - val_accuracy: 0.9580\n",
            "Epoch 6/100\n",
            "100/100 - 18s - loss: 0.1512 - accuracy: 0.9490 - val_loss: 0.0993 - val_accuracy: 0.9660\n",
            "Epoch 7/100\n",
            "100/100 - 19s - loss: 0.1664 - accuracy: 0.9395 - val_loss: 0.1315 - val_accuracy: 0.9570\n",
            "Epoch 8/100\n",
            "100/100 - 19s - loss: 0.1502 - accuracy: 0.9465 - val_loss: 0.0925 - val_accuracy: 0.9710\n",
            "Epoch 9/100\n",
            "100/100 - 19s - loss: 0.1524 - accuracy: 0.9425 - val_loss: 0.1110 - val_accuracy: 0.9710\n",
            "Epoch 10/100\n",
            "100/100 - 19s - loss: 0.1443 - accuracy: 0.9440 - val_loss: 0.1400 - val_accuracy: 0.9630\n",
            "Epoch 11/100\n",
            "100/100 - 19s - loss: 0.1329 - accuracy: 0.9505 - val_loss: 0.1048 - val_accuracy: 0.9690\n",
            "Epoch 12/100\n",
            "100/100 - 19s - loss: 0.1312 - accuracy: 0.9460 - val_loss: 0.1159 - val_accuracy: 0.9620\n",
            "Epoch 13/100\n",
            "100/100 - 18s - loss: 0.1224 - accuracy: 0.9595 - val_loss: 0.1201 - val_accuracy: 0.9650\n",
            "Epoch 14/100\n",
            "100/100 - 18s - loss: 0.1216 - accuracy: 0.9530 - val_loss: 0.1239 - val_accuracy: 0.9700\n",
            "Epoch 15/100\n",
            "100/100 - 18s - loss: 0.1409 - accuracy: 0.9505 - val_loss: 0.1184 - val_accuracy: 0.9650\n",
            "Epoch 16/100\n",
            "100/100 - 18s - loss: 0.1331 - accuracy: 0.9545 - val_loss: 0.1662 - val_accuracy: 0.9610\n",
            "Epoch 17/100\n",
            "100/100 - 18s - loss: 0.1240 - accuracy: 0.9615 - val_loss: 0.1571 - val_accuracy: 0.9590\n",
            "Epoch 18/100\n",
            "100/100 - 18s - loss: 0.1175 - accuracy: 0.9610 - val_loss: 0.1411 - val_accuracy: 0.9650\n",
            "Epoch 19/100\n",
            "100/100 - 19s - loss: 0.0943 - accuracy: 0.9660 - val_loss: 0.1846 - val_accuracy: 0.9560\n",
            "Epoch 20/100\n",
            "100/100 - 18s - loss: 0.1226 - accuracy: 0.9590 - val_loss: 0.1107 - val_accuracy: 0.9670\n",
            "Epoch 21/100\n",
            "100/100 - 18s - loss: 0.1054 - accuracy: 0.9610 - val_loss: 0.1480 - val_accuracy: 0.9680\n",
            "Epoch 22/100\n",
            "100/100 - 18s - loss: 0.1219 - accuracy: 0.9630 - val_loss: 0.1460 - val_accuracy: 0.9610\n",
            "Epoch 23/100\n",
            "100/100 - 18s - loss: 0.1103 - accuracy: 0.9610 - val_loss: 0.1498 - val_accuracy: 0.9540\n",
            "Epoch 24/100\n",
            "100/100 - 18s - loss: 0.0991 - accuracy: 0.9650 - val_loss: 0.1458 - val_accuracy: 0.9670\n",
            "Epoch 25/100\n",
            "100/100 - 18s - loss: 0.1020 - accuracy: 0.9650 - val_loss: 0.1102 - val_accuracy: 0.9710\n",
            "Epoch 26/100\n",
            "100/100 - 18s - loss: 0.1139 - accuracy: 0.9600 - val_loss: 0.1099 - val_accuracy: 0.9730\n",
            "Epoch 27/100\n",
            "100/100 - 18s - loss: 0.0860 - accuracy: 0.9730 - val_loss: 0.1490 - val_accuracy: 0.9610\n",
            "Epoch 28/100\n",
            "100/100 - 18s - loss: 0.0956 - accuracy: 0.9680 - val_loss: 0.1245 - val_accuracy: 0.9710\n",
            "Epoch 29/100\n",
            "100/100 - 18s - loss: 0.1074 - accuracy: 0.9625 - val_loss: 0.1026 - val_accuracy: 0.9730\n",
            "Epoch 30/100\n",
            "100/100 - 18s - loss: 0.1094 - accuracy: 0.9620 - val_loss: 0.1102 - val_accuracy: 0.9670\n",
            "Epoch 31/100\n",
            "100/100 - 18s - loss: 0.0919 - accuracy: 0.9680 - val_loss: 0.1303 - val_accuracy: 0.9700\n",
            "Epoch 32/100\n",
            "100/100 - 18s - loss: 0.0880 - accuracy: 0.9700 - val_loss: 0.1240 - val_accuracy: 0.9610\n",
            "Epoch 33/100\n",
            "100/100 - 18s - loss: 0.0946 - accuracy: 0.9660 - val_loss: 0.1261 - val_accuracy: 0.9650\n",
            "Epoch 34/100\n",
            "100/100 - 18s - loss: 0.0849 - accuracy: 0.9690 - val_loss: 0.1528 - val_accuracy: 0.9590\n",
            "Epoch 35/100\n",
            "100/100 - 18s - loss: 0.0989 - accuracy: 0.9705 - val_loss: 0.1363 - val_accuracy: 0.9650\n",
            "Epoch 36/100\n",
            "100/100 - 18s - loss: 0.0892 - accuracy: 0.9755 - val_loss: 0.1870 - val_accuracy: 0.9600\n",
            "Epoch 37/100\n",
            "100/100 - 18s - loss: 0.0978 - accuracy: 0.9720 - val_loss: 0.1193 - val_accuracy: 0.9710\n",
            "Epoch 38/100\n",
            "100/100 - 18s - loss: 0.0851 - accuracy: 0.9740 - val_loss: 0.1311 - val_accuracy: 0.9670\n",
            "Epoch 39/100\n",
            "100/100 - 19s - loss: 0.0798 - accuracy: 0.9685 - val_loss: 0.1207 - val_accuracy: 0.9700\n",
            "Epoch 40/100\n",
            "100/100 - 19s - loss: 0.0770 - accuracy: 0.9745 - val_loss: 0.1424 - val_accuracy: 0.9640\n",
            "Epoch 41/100\n",
            "100/100 - 19s - loss: 0.0666 - accuracy: 0.9760 - val_loss: 0.1531 - val_accuracy: 0.9670\n",
            "Epoch 42/100\n",
            "100/100 - 19s - loss: 0.0788 - accuracy: 0.9755 - val_loss: 0.1302 - val_accuracy: 0.9660\n",
            "Epoch 43/100\n",
            "100/100 - 18s - loss: 0.0901 - accuracy: 0.9695 - val_loss: 0.1388 - val_accuracy: 0.9670\n",
            "Epoch 44/100\n",
            "100/100 - 18s - loss: 0.0976 - accuracy: 0.9680 - val_loss: 0.1448 - val_accuracy: 0.9620\n",
            "Epoch 45/100\n",
            "100/100 - 18s - loss: 0.0823 - accuracy: 0.9745 - val_loss: 0.1706 - val_accuracy: 0.9640\n",
            "Epoch 46/100\n",
            "100/100 - 18s - loss: 0.0869 - accuracy: 0.9730 - val_loss: 0.1289 - val_accuracy: 0.9710\n",
            "Epoch 47/100\n",
            "100/100 - 18s - loss: 0.0979 - accuracy: 0.9690 - val_loss: 0.1485 - val_accuracy: 0.9640\n",
            "Epoch 48/100\n",
            "100/100 - 18s - loss: 0.0662 - accuracy: 0.9765 - val_loss: 0.1607 - val_accuracy: 0.9660\n",
            "Epoch 49/100\n",
            "100/100 - 18s - loss: 0.0633 - accuracy: 0.9820 - val_loss: 0.1402 - val_accuracy: 0.9690\n",
            "Epoch 50/100\n",
            "100/100 - 18s - loss: 0.0826 - accuracy: 0.9705 - val_loss: 0.1546 - val_accuracy: 0.9590\n",
            "Epoch 51/100\n",
            "100/100 - 18s - loss: 0.0658 - accuracy: 0.9800 - val_loss: 0.1709 - val_accuracy: 0.9610\n",
            "Epoch 52/100\n",
            "100/100 - 18s - loss: 0.0657 - accuracy: 0.9765 - val_loss: 0.1550 - val_accuracy: 0.9660\n",
            "Epoch 53/100\n",
            "100/100 - 18s - loss: 0.0640 - accuracy: 0.9795 - val_loss: 0.1643 - val_accuracy: 0.9660\n",
            "Epoch 54/100\n",
            "100/100 - 18s - loss: 0.0667 - accuracy: 0.9780 - val_loss: 0.1866 - val_accuracy: 0.9710\n",
            "Epoch 55/100\n",
            "100/100 - 18s - loss: 0.0706 - accuracy: 0.9770 - val_loss: 0.1587 - val_accuracy: 0.9620\n",
            "Epoch 56/100\n",
            "100/100 - 18s - loss: 0.0676 - accuracy: 0.9775 - val_loss: 0.1381 - val_accuracy: 0.9680\n",
            "Epoch 57/100\n",
            "100/100 - 18s - loss: 0.0573 - accuracy: 0.9825 - val_loss: 0.1738 - val_accuracy: 0.9680\n",
            "Epoch 58/100\n",
            "100/100 - 18s - loss: 0.0592 - accuracy: 0.9810 - val_loss: 0.1595 - val_accuracy: 0.9660\n",
            "Epoch 59/100\n",
            "100/100 - 18s - loss: 0.0841 - accuracy: 0.9750 - val_loss: 0.1624 - val_accuracy: 0.9660\n",
            "Epoch 60/100\n",
            "100/100 - 18s - loss: 0.0586 - accuracy: 0.9815 - val_loss: 0.1489 - val_accuracy: 0.9690\n",
            "Epoch 61/100\n",
            "100/100 - 18s - loss: 0.0470 - accuracy: 0.9810 - val_loss: 0.1506 - val_accuracy: 0.9680\n",
            "Epoch 62/100\n",
            "100/100 - 18s - loss: 0.0679 - accuracy: 0.9795 - val_loss: 0.1708 - val_accuracy: 0.9700\n",
            "Epoch 63/100\n",
            "100/100 - 18s - loss: 0.0722 - accuracy: 0.9825 - val_loss: 0.1448 - val_accuracy: 0.9700\n",
            "Epoch 64/100\n",
            "100/100 - 18s - loss: 0.0486 - accuracy: 0.9815 - val_loss: 0.1796 - val_accuracy: 0.9690\n",
            "Epoch 65/100\n",
            "100/100 - 18s - loss: 0.0679 - accuracy: 0.9820 - val_loss: 0.1723 - val_accuracy: 0.9640\n",
            "Epoch 66/100\n",
            "100/100 - 18s - loss: 0.0697 - accuracy: 0.9790 - val_loss: 0.1347 - val_accuracy: 0.9690\n",
            "Epoch 67/100\n",
            "100/100 - 18s - loss: 0.0571 - accuracy: 0.9815 - val_loss: 0.1561 - val_accuracy: 0.9700\n",
            "Epoch 68/100\n",
            "100/100 - 18s - loss: 0.0532 - accuracy: 0.9825 - val_loss: 0.1407 - val_accuracy: 0.9710\n",
            "Epoch 69/100\n",
            "100/100 - 18s - loss: 0.0692 - accuracy: 0.9805 - val_loss: 0.1524 - val_accuracy: 0.9670\n",
            "Epoch 70/100\n",
            "100/100 - 18s - loss: 0.0540 - accuracy: 0.9805 - val_loss: 0.1609 - val_accuracy: 0.9660\n",
            "Epoch 71/100\n",
            "100/100 - 18s - loss: 0.0539 - accuracy: 0.9845 - val_loss: 0.1606 - val_accuracy: 0.9700\n",
            "Epoch 72/100\n",
            "100/100 - 18s - loss: 0.0521 - accuracy: 0.9835 - val_loss: 0.1587 - val_accuracy: 0.9690\n",
            "Epoch 73/100\n",
            "100/100 - 18s - loss: 0.0469 - accuracy: 0.9845 - val_loss: 0.1709 - val_accuracy: 0.9670\n",
            "Epoch 74/100\n",
            "100/100 - 18s - loss: 0.0638 - accuracy: 0.9820 - val_loss: 0.1708 - val_accuracy: 0.9660\n",
            "Epoch 75/100\n",
            "100/100 - 18s - loss: 0.0589 - accuracy: 0.9850 - val_loss: 0.1423 - val_accuracy: 0.9630\n",
            "Epoch 76/100\n",
            "100/100 - 18s - loss: 0.0461 - accuracy: 0.9845 - val_loss: 0.1624 - val_accuracy: 0.9680\n",
            "Epoch 77/100\n",
            "100/100 - 18s - loss: 0.0374 - accuracy: 0.9900 - val_loss: 0.1336 - val_accuracy: 0.9670\n",
            "Epoch 78/100\n",
            "100/100 - 18s - loss: 0.0472 - accuracy: 0.9855 - val_loss: 0.1733 - val_accuracy: 0.9650\n",
            "Epoch 79/100\n",
            "100/100 - 18s - loss: 0.0563 - accuracy: 0.9825 - val_loss: 0.1811 - val_accuracy: 0.9620\n",
            "Epoch 80/100\n",
            "100/100 - 18s - loss: 0.0425 - accuracy: 0.9830 - val_loss: 0.1651 - val_accuracy: 0.9660\n",
            "Epoch 81/100\n",
            "100/100 - 18s - loss: 0.0504 - accuracy: 0.9890 - val_loss: 0.2021 - val_accuracy: 0.9680\n",
            "Epoch 82/100\n",
            "100/100 - 18s - loss: 0.0491 - accuracy: 0.9805 - val_loss: 0.1607 - val_accuracy: 0.9670\n",
            "Epoch 83/100\n",
            "100/100 - 18s - loss: 0.0464 - accuracy: 0.9860 - val_loss: 0.1755 - val_accuracy: 0.9670\n",
            "Epoch 84/100\n",
            "100/100 - 18s - loss: 0.0479 - accuracy: 0.9850 - val_loss: 0.1664 - val_accuracy: 0.9730\n",
            "Epoch 85/100\n",
            "100/100 - 18s - loss: 0.0585 - accuracy: 0.9820 - val_loss: 0.1596 - val_accuracy: 0.9690\n",
            "Epoch 86/100\n",
            "100/100 - 18s - loss: 0.0449 - accuracy: 0.9890 - val_loss: 0.1674 - val_accuracy: 0.9650\n",
            "Epoch 87/100\n",
            "100/100 - 18s - loss: 0.0498 - accuracy: 0.9835 - val_loss: 0.1619 - val_accuracy: 0.9660\n",
            "Epoch 88/100\n",
            "100/100 - 18s - loss: 0.0391 - accuracy: 0.9865 - val_loss: 0.1641 - val_accuracy: 0.9670\n",
            "Epoch 89/100\n",
            "100/100 - 18s - loss: 0.0482 - accuracy: 0.9835 - val_loss: 0.1972 - val_accuracy: 0.9620\n",
            "Epoch 90/100\n",
            "100/100 - 18s - loss: 0.0428 - accuracy: 0.9865 - val_loss: 0.1703 - val_accuracy: 0.9670\n",
            "Epoch 91/100\n",
            "100/100 - 18s - loss: 0.0434 - accuracy: 0.9880 - val_loss: 0.1475 - val_accuracy: 0.9680\n",
            "Epoch 92/100\n",
            "100/100 - 18s - loss: 0.0313 - accuracy: 0.9885 - val_loss: 0.1736 - val_accuracy: 0.9640\n",
            "Epoch 93/100\n",
            "100/100 - 18s - loss: 0.0464 - accuracy: 0.9855 - val_loss: 0.1994 - val_accuracy: 0.9650\n",
            "Epoch 94/100\n",
            "100/100 - 18s - loss: 0.0478 - accuracy: 0.9870 - val_loss: 0.1484 - val_accuracy: 0.9690\n",
            "Epoch 95/100\n",
            "100/100 - 18s - loss: 0.0451 - accuracy: 0.9835 - val_loss: 0.1551 - val_accuracy: 0.9710\n",
            "Epoch 96/100\n",
            "100/100 - 18s - loss: 0.0496 - accuracy: 0.9855 - val_loss: 0.1619 - val_accuracy: 0.9690\n",
            "Epoch 97/100\n",
            "100/100 - 18s - loss: 0.0350 - accuracy: 0.9875 - val_loss: 0.1594 - val_accuracy: 0.9700\n",
            "Epoch 98/100\n",
            "100/100 - 18s - loss: 0.0371 - accuracy: 0.9875 - val_loss: 0.1393 - val_accuracy: 0.9740\n",
            "Epoch 99/100\n",
            "100/100 - 18s - loss: 0.0364 - accuracy: 0.9900 - val_loss: 0.1482 - val_accuracy: 0.9740\n",
            "Epoch 100/100\n",
            "100/100 - 18s - loss: 0.0329 - accuracy: 0.9890 - val_loss: 0.2146 - val_accuracy: 0.9600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "REHMPAyAnXeV",
        "outputId": "39553675-c9e1-4f82-85f2-de3c962574e2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-1FteHbsOUy"
      },
      "source": [
        "This is another overfitting situation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6q4qwFNwq0T"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "xx = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "xx = layers.Dense(1024, activation='relu')(xx)\n",
        "# Add a dropout rate of 0.2\n",
        "xx = layers.Dropout(0.2)(xx)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "xx = layers.Dense  (1, activation='sigmoid')(xx)           \n",
        "\n",
        "model2 = Model( pre_trained_model.input, xx) \n",
        "\n",
        "model2.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpe6rOgsw4Wv",
        "outputId": "6b018e87-9a53-4ff8-8dcd-43d02a6db9ea"
      },
      "source": [
        "history2 = model2.fit(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.3332 - accuracy: 0.8670 - val_loss: 0.1122 - val_accuracy: 0.9570\n",
            "Epoch 2/100\n",
            "100/100 - 18s - loss: 0.2314 - accuracy: 0.9155 - val_loss: 0.1388 - val_accuracy: 0.9540\n",
            "Epoch 3/100\n",
            "100/100 - 18s - loss: 0.2024 - accuracy: 0.9265 - val_loss: 0.1138 - val_accuracy: 0.9620\n",
            "Epoch 4/100\n",
            "100/100 - 18s - loss: 0.2023 - accuracy: 0.9280 - val_loss: 0.1227 - val_accuracy: 0.9540\n",
            "Epoch 5/100\n",
            "100/100 - 18s - loss: 0.1910 - accuracy: 0.9370 - val_loss: 0.1171 - val_accuracy: 0.9570\n",
            "Epoch 6/100\n",
            "100/100 - 18s - loss: 0.1935 - accuracy: 0.9335 - val_loss: 0.0986 - val_accuracy: 0.9660\n",
            "Epoch 7/100\n",
            "100/100 - 18s - loss: 0.1756 - accuracy: 0.9410 - val_loss: 0.1046 - val_accuracy: 0.9690\n",
            "Epoch 8/100\n",
            "100/100 - 18s - loss: 0.1723 - accuracy: 0.9365 - val_loss: 0.1025 - val_accuracy: 0.9670\n",
            "Epoch 9/100\n",
            "100/100 - 18s - loss: 0.1553 - accuracy: 0.9445 - val_loss: 0.0926 - val_accuracy: 0.9690\n",
            "Epoch 10/100\n",
            "100/100 - 18s - loss: 0.1742 - accuracy: 0.9385 - val_loss: 0.0802 - val_accuracy: 0.9700\n",
            "Epoch 11/100\n",
            "100/100 - 18s - loss: 0.1385 - accuracy: 0.9450 - val_loss: 0.1062 - val_accuracy: 0.9690\n",
            "Epoch 12/100\n",
            "100/100 - 18s - loss: 0.1526 - accuracy: 0.9510 - val_loss: 0.1001 - val_accuracy: 0.9710\n",
            "Epoch 13/100\n",
            "100/100 - 18s - loss: 0.1328 - accuracy: 0.9525 - val_loss: 0.0999 - val_accuracy: 0.9670\n",
            "Epoch 14/100\n",
            "100/100 - 18s - loss: 0.1541 - accuracy: 0.9545 - val_loss: 0.1313 - val_accuracy: 0.9620\n",
            "Epoch 15/100\n",
            "100/100 - 18s - loss: 0.1517 - accuracy: 0.9520 - val_loss: 0.1136 - val_accuracy: 0.9740\n",
            "Epoch 16/100\n",
            "100/100 - 18s - loss: 0.1341 - accuracy: 0.9580 - val_loss: 0.0988 - val_accuracy: 0.9730\n",
            "Epoch 17/100\n",
            "100/100 - 18s - loss: 0.1342 - accuracy: 0.9540 - val_loss: 0.1116 - val_accuracy: 0.9710\n",
            "Epoch 18/100\n",
            "100/100 - 18s - loss: 0.1402 - accuracy: 0.9545 - val_loss: 0.2317 - val_accuracy: 0.9470\n",
            "Epoch 19/100\n",
            "100/100 - 18s - loss: 0.1331 - accuracy: 0.9550 - val_loss: 0.1568 - val_accuracy: 0.9570\n",
            "Epoch 20/100\n",
            "100/100 - 18s - loss: 0.1375 - accuracy: 0.9600 - val_loss: 0.1087 - val_accuracy: 0.9680\n",
            "Epoch 21/100\n",
            "100/100 - 18s - loss: 0.1205 - accuracy: 0.9610 - val_loss: 0.1406 - val_accuracy: 0.9670\n",
            "Epoch 22/100\n",
            "100/100 - 18s - loss: 0.1246 - accuracy: 0.9640 - val_loss: 0.1282 - val_accuracy: 0.9720\n",
            "Epoch 23/100\n",
            "100/100 - 18s - loss: 0.1204 - accuracy: 0.9635 - val_loss: 0.1369 - val_accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "100/100 - 18s - loss: 0.1352 - accuracy: 0.9520 - val_loss: 0.1397 - val_accuracy: 0.9660\n",
            "Epoch 25/100\n",
            "100/100 - 18s - loss: 0.1216 - accuracy: 0.9565 - val_loss: 0.1629 - val_accuracy: 0.9620\n",
            "Epoch 26/100\n",
            "100/100 - 18s - loss: 0.1074 - accuracy: 0.9590 - val_loss: 0.1538 - val_accuracy: 0.9670\n",
            "Epoch 27/100\n",
            "100/100 - 18s - loss: 0.1216 - accuracy: 0.9630 - val_loss: 0.1447 - val_accuracy: 0.9710\n",
            "Epoch 28/100\n",
            "100/100 - 18s - loss: 0.1169 - accuracy: 0.9635 - val_loss: 0.2095 - val_accuracy: 0.9530\n",
            "Epoch 29/100\n",
            "100/100 - 18s - loss: 0.1030 - accuracy: 0.9700 - val_loss: 0.1746 - val_accuracy: 0.9560\n",
            "Epoch 30/100\n",
            "100/100 - 19s - loss: 0.1439 - accuracy: 0.9590 - val_loss: 0.1409 - val_accuracy: 0.9650\n",
            "Epoch 31/100\n",
            "100/100 - 18s - loss: 0.0981 - accuracy: 0.9665 - val_loss: 0.1540 - val_accuracy: 0.9670\n",
            "Epoch 32/100\n",
            "100/100 - 18s - loss: 0.1208 - accuracy: 0.9685 - val_loss: 0.1446 - val_accuracy: 0.9690\n",
            "Epoch 33/100\n",
            "100/100 - 18s - loss: 0.1247 - accuracy: 0.9660 - val_loss: 0.1472 - val_accuracy: 0.9670\n",
            "Epoch 34/100\n",
            "100/100 - 18s - loss: 0.1088 - accuracy: 0.9650 - val_loss: 0.1713 - val_accuracy: 0.9620\n",
            "Epoch 35/100\n",
            "100/100 - 18s - loss: 0.1223 - accuracy: 0.9585 - val_loss: 0.1035 - val_accuracy: 0.9670\n",
            "Epoch 36/100\n",
            "100/100 - 18s - loss: 0.1118 - accuracy: 0.9645 - val_loss: 0.1339 - val_accuracy: 0.9700\n",
            "Epoch 37/100\n",
            "100/100 - 18s - loss: 0.1129 - accuracy: 0.9635 - val_loss: 0.1390 - val_accuracy: 0.9690\n",
            "Epoch 38/100\n",
            "100/100 - 18s - loss: 0.0946 - accuracy: 0.9705 - val_loss: 0.1468 - val_accuracy: 0.9650\n",
            "Epoch 39/100\n",
            "100/100 - 18s - loss: 0.0759 - accuracy: 0.9730 - val_loss: 0.1537 - val_accuracy: 0.9630\n",
            "Epoch 40/100\n",
            "100/100 - 18s - loss: 0.1032 - accuracy: 0.9700 - val_loss: 0.1441 - val_accuracy: 0.9700\n",
            "Epoch 41/100\n",
            "100/100 - 18s - loss: 0.0968 - accuracy: 0.9675 - val_loss: 0.1396 - val_accuracy: 0.9700\n",
            "Epoch 42/100\n",
            "100/100 - 18s - loss: 0.0959 - accuracy: 0.9675 - val_loss: 0.1300 - val_accuracy: 0.9710\n",
            "Epoch 43/100\n",
            "100/100 - 18s - loss: 0.0850 - accuracy: 0.9680 - val_loss: 0.1466 - val_accuracy: 0.9670\n",
            "Epoch 44/100\n",
            "100/100 - 18s - loss: 0.0688 - accuracy: 0.9780 - val_loss: 0.1524 - val_accuracy: 0.9690\n",
            "Epoch 45/100\n",
            "100/100 - 18s - loss: 0.0968 - accuracy: 0.9685 - val_loss: 0.1470 - val_accuracy: 0.9680\n",
            "Epoch 46/100\n",
            "100/100 - 18s - loss: 0.0733 - accuracy: 0.9740 - val_loss: 0.1439 - val_accuracy: 0.9730\n",
            "Epoch 47/100\n",
            "100/100 - 18s - loss: 0.0846 - accuracy: 0.9695 - val_loss: 0.1547 - val_accuracy: 0.9700\n",
            "Epoch 48/100\n",
            "100/100 - 18s - loss: 0.0920 - accuracy: 0.9705 - val_loss: 0.1408 - val_accuracy: 0.9700\n",
            "Epoch 49/100\n",
            "100/100 - 18s - loss: 0.0860 - accuracy: 0.9750 - val_loss: 0.1634 - val_accuracy: 0.9680\n",
            "Epoch 50/100\n",
            "100/100 - 18s - loss: 0.0975 - accuracy: 0.9675 - val_loss: 0.1629 - val_accuracy: 0.9670\n",
            "Epoch 51/100\n",
            "100/100 - 18s - loss: 0.0726 - accuracy: 0.9735 - val_loss: 0.1434 - val_accuracy: 0.9730\n",
            "Epoch 52/100\n",
            "100/100 - 18s - loss: 0.0876 - accuracy: 0.9760 - val_loss: 0.1499 - val_accuracy: 0.9720\n",
            "Epoch 53/100\n",
            "100/100 - 18s - loss: 0.0790 - accuracy: 0.9720 - val_loss: 0.1422 - val_accuracy: 0.9710\n",
            "Epoch 54/100\n",
            "100/100 - 18s - loss: 0.0660 - accuracy: 0.9790 - val_loss: 0.1400 - val_accuracy: 0.9710\n",
            "Epoch 55/100\n",
            "100/100 - 18s - loss: 0.0823 - accuracy: 0.9800 - val_loss: 0.1514 - val_accuracy: 0.9760\n",
            "Epoch 56/100\n",
            "100/100 - 18s - loss: 0.0823 - accuracy: 0.9735 - val_loss: 0.1712 - val_accuracy: 0.9620\n",
            "Epoch 57/100\n",
            "100/100 - 18s - loss: 0.0619 - accuracy: 0.9815 - val_loss: 0.1581 - val_accuracy: 0.9650\n",
            "Epoch 58/100\n",
            "100/100 - 18s - loss: 0.0913 - accuracy: 0.9760 - val_loss: 0.1405 - val_accuracy: 0.9750\n",
            "Epoch 59/100\n",
            "100/100 - 18s - loss: 0.0766 - accuracy: 0.9735 - val_loss: 0.2520 - val_accuracy: 0.9520\n",
            "Epoch 60/100\n",
            "100/100 - 18s - loss: 0.0695 - accuracy: 0.9750 - val_loss: 0.1569 - val_accuracy: 0.9730\n",
            "Epoch 61/100\n",
            "100/100 - 18s - loss: 0.0868 - accuracy: 0.9725 - val_loss: 0.1506 - val_accuracy: 0.9720\n",
            "Epoch 62/100\n",
            "100/100 - 18s - loss: 0.0842 - accuracy: 0.9750 - val_loss: 0.1825 - val_accuracy: 0.9650\n",
            "Epoch 63/100\n",
            "100/100 - 18s - loss: 0.0673 - accuracy: 0.9765 - val_loss: 0.1591 - val_accuracy: 0.9720\n",
            "Epoch 64/100\n",
            "100/100 - 18s - loss: 0.0731 - accuracy: 0.9775 - val_loss: 0.1686 - val_accuracy: 0.9700\n",
            "Epoch 65/100\n",
            "100/100 - 18s - loss: 0.0382 - accuracy: 0.9855 - val_loss: 0.1899 - val_accuracy: 0.9690\n",
            "Epoch 66/100\n",
            "100/100 - 18s - loss: 0.0813 - accuracy: 0.9720 - val_loss: 0.1566 - val_accuracy: 0.9690\n",
            "Epoch 67/100\n",
            "100/100 - 18s - loss: 0.0895 - accuracy: 0.9715 - val_loss: 0.1673 - val_accuracy: 0.9720\n",
            "Epoch 68/100\n",
            "100/100 - 18s - loss: 0.0463 - accuracy: 0.9815 - val_loss: 0.1544 - val_accuracy: 0.9720\n",
            "Epoch 69/100\n",
            "100/100 - 18s - loss: 0.0792 - accuracy: 0.9765 - val_loss: 0.1539 - val_accuracy: 0.9700\n",
            "Epoch 70/100\n",
            "100/100 - 18s - loss: 0.0792 - accuracy: 0.9760 - val_loss: 0.1345 - val_accuracy: 0.9730\n",
            "Epoch 71/100\n",
            "100/100 - 18s - loss: 0.0700 - accuracy: 0.9795 - val_loss: 0.1498 - val_accuracy: 0.9690\n",
            "Epoch 72/100\n",
            "100/100 - 18s - loss: 0.0674 - accuracy: 0.9785 - val_loss: 0.1415 - val_accuracy: 0.9720\n",
            "Epoch 73/100\n",
            "100/100 - 18s - loss: 0.0630 - accuracy: 0.9800 - val_loss: 0.1552 - val_accuracy: 0.9710\n",
            "Epoch 74/100\n",
            "100/100 - 18s - loss: 0.0658 - accuracy: 0.9750 - val_loss: 0.1572 - val_accuracy: 0.9700\n",
            "Epoch 75/100\n",
            "100/100 - 18s - loss: 0.0623 - accuracy: 0.9770 - val_loss: 0.1811 - val_accuracy: 0.9690\n",
            "Epoch 76/100\n",
            "100/100 - 18s - loss: 0.0634 - accuracy: 0.9795 - val_loss: 0.1796 - val_accuracy: 0.9680\n",
            "Epoch 77/100\n",
            "100/100 - 18s - loss: 0.0716 - accuracy: 0.9760 - val_loss: 0.1783 - val_accuracy: 0.9700\n",
            "Epoch 78/100\n",
            "100/100 - 18s - loss: 0.0647 - accuracy: 0.9790 - val_loss: 0.1502 - val_accuracy: 0.9720\n",
            "Epoch 79/100\n",
            "100/100 - 18s - loss: 0.0724 - accuracy: 0.9775 - val_loss: 0.1584 - val_accuracy: 0.9700\n",
            "Epoch 80/100\n",
            "100/100 - 18s - loss: 0.0555 - accuracy: 0.9880 - val_loss: 0.1911 - val_accuracy: 0.9680\n",
            "Epoch 81/100\n",
            "100/100 - 18s - loss: 0.0572 - accuracy: 0.9820 - val_loss: 0.1965 - val_accuracy: 0.9680\n",
            "Epoch 82/100\n",
            "100/100 - 18s - loss: 0.0621 - accuracy: 0.9815 - val_loss: 0.1849 - val_accuracy: 0.9620\n",
            "Epoch 83/100\n",
            "100/100 - 18s - loss: 0.0526 - accuracy: 0.9835 - val_loss: 0.1809 - val_accuracy: 0.9680\n",
            "Epoch 84/100\n",
            "100/100 - 18s - loss: 0.0576 - accuracy: 0.9810 - val_loss: 0.1492 - val_accuracy: 0.9690\n",
            "Epoch 85/100\n",
            "100/100 - 18s - loss: 0.0527 - accuracy: 0.9840 - val_loss: 0.1616 - val_accuracy: 0.9710\n",
            "Epoch 86/100\n",
            "100/100 - 18s - loss: 0.0811 - accuracy: 0.9755 - val_loss: 0.1627 - val_accuracy: 0.9690\n",
            "Epoch 87/100\n",
            "100/100 - 18s - loss: 0.0526 - accuracy: 0.9870 - val_loss: 0.1525 - val_accuracy: 0.9710\n",
            "Epoch 88/100\n",
            "100/100 - 18s - loss: 0.0450 - accuracy: 0.9835 - val_loss: 0.1609 - val_accuracy: 0.9690\n",
            "Epoch 89/100\n",
            "100/100 - 18s - loss: 0.0590 - accuracy: 0.9825 - val_loss: 0.1645 - val_accuracy: 0.9680\n",
            "Epoch 90/100\n",
            "100/100 - 18s - loss: 0.0742 - accuracy: 0.9800 - val_loss: 0.1427 - val_accuracy: 0.9750\n",
            "Epoch 91/100\n",
            "100/100 - 18s - loss: 0.0812 - accuracy: 0.9745 - val_loss: 0.1352 - val_accuracy: 0.9700\n",
            "Epoch 92/100\n",
            "100/100 - 18s - loss: 0.0642 - accuracy: 0.9775 - val_loss: 0.1546 - val_accuracy: 0.9670\n",
            "Epoch 93/100\n",
            "100/100 - 18s - loss: 0.0590 - accuracy: 0.9835 - val_loss: 0.1719 - val_accuracy: 0.9640\n",
            "Epoch 94/100\n",
            "100/100 - 18s - loss: 0.0340 - accuracy: 0.9875 - val_loss: 0.1756 - val_accuracy: 0.9650\n",
            "Epoch 95/100\n",
            "100/100 - 18s - loss: 0.0583 - accuracy: 0.9810 - val_loss: 0.1570 - val_accuracy: 0.9730\n",
            "Epoch 96/100\n",
            "100/100 - 18s - loss: 0.0693 - accuracy: 0.9840 - val_loss: 0.1691 - val_accuracy: 0.9720\n",
            "Epoch 97/100\n",
            "100/100 - 18s - loss: 0.0595 - accuracy: 0.9800 - val_loss: 0.1577 - val_accuracy: 0.9670\n",
            "Epoch 98/100\n",
            "100/100 - 18s - loss: 0.0607 - accuracy: 0.9820 - val_loss: 0.1712 - val_accuracy: 0.9730\n",
            "Epoch 99/100\n",
            "100/100 - 18s - loss: 0.0470 - accuracy: 0.9845 - val_loss: 0.1663 - val_accuracy: 0.9670\n",
            "Epoch 100/100\n",
            "100/100 - 18s - loss: 0.0421 - accuracy: 0.9870 - val_loss: 0.1763 - val_accuracy: 0.9690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "NKjLyiClw7YX",
        "outputId": "7b3dcc4b-4faf-48a2-9c96-2c64129e292a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history2.history['accuracy']\n",
        "val_acc = history2.history['val_accuracy']\n",
        "loss = history2.history['loss']\n",
        "val_loss = history2.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}